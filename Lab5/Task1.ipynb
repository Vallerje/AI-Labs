{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PzBfdnzEAz8e"
      },
      "outputs": [],
      "source": [
        "import pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q1dmksgkB8fY"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "d1OKGQT5Bbfl",
        "outputId": "4a2b8fa3-c295-4db5-9999-224e6412564f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/03/10 10:25:10 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Titanic Data</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x1077ba120>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Titanic Data\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.host\", \"localhost\") \\\n",
        "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"file:///tmp/spark-warehouse\") \\\n",
        "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFkZVxSWChxM",
        "outputId": "0f86f56e-8c6d-424f-ca1d-731b46d358e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male| 35|    0|    0|          373450|   8.05| NULL|       S|\n",
            "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = (spark.read\n",
        "      .format(\"csv\")\n",
        "      .option(\"header\", \"true\")\n",
        "      .load(\"Data/titanic/train.csv\")\n",
        "      )\n",
        "\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En-HJGEdDkC4",
        "outputId": "05b2561a-94cf-47ce-a924-7e81f4b032e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-------+--------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
            "+--------+------+------+----+-------+--------+\n",
            "|     0.0|   3.0|  male|22.0|   7.25|       S|\n",
            "|     1.0|   1.0|female|38.0|71.2833|       C|\n",
            "|     1.0|   3.0|female|26.0|  7.925|       S|\n",
            "|     1.0|   1.0|female|35.0|   53.1|       S|\n",
            "+--------+------+------+----+-------+--------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "dataset = df.select(col(\"Survived\").cast(\"float\"),\n",
        "                      col(\"Pclass\").cast(\"float\"),\n",
        "                      col(\"Sex\"),\n",
        "                      col(\"Age\").cast(\"float\"),\n",
        "                      col(\"Fare\").cast(\"float\"),\n",
        "                      col(\"Embarked\"))\n",
        "\n",
        "dataset.show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UoaL2QfSpPD",
        "outputId": "c14c26f1-0ef7-4b97-c9a2-c3d7fefb0283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+---+---+----+--------+\n",
            "|Survived|Pclass|Sex|Age|Fare|Embarked|\n",
            "+--------+------+---+---+----+--------+\n",
            "|       0|     0|  0|177|   0|       2|\n",
            "+--------+------+---+---+----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import isnull, when, count, col\n",
        "\n",
        "dataset.select([count(when(isnull(c), c)).alias(c) for c in dataset.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lcXK6hAPTFDM"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.replace('?', None).dropna(how='any')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEi7FzO2TQbd",
        "outputId": "75e98900-f426-4980-ade9-90ade5af7108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+---+---+----+--------+\n",
            "|Survived|Pclass|Sex|Age|Fare|Embarked|\n",
            "+--------+------+---+---+----+--------+\n",
            "|       0|     0|  0|  0|   0|       0|\n",
            "+--------+------+---+---+----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset.select([count(when(isnull(c), c)).alias(c) for c in dataset.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bF5ly3OWTTMW"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "dataset = StringIndexer(\n",
        "    inputCol = 'Sex',\n",
        "    outputCol = 'Gender',\n",
        "    handleInvalid = 'keep').fit(dataset).transform(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q6HTtsz_Udds"
      },
      "outputs": [],
      "source": [
        "dataset = StringIndexer(\n",
        "    inputCol = 'Embarked',\n",
        "    outputCol = 'Boarded',\n",
        "    handleInvalid = 'keep').fit(dataset).transform(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI2O2OXnULLl",
        "outputId": "799df831-52f2-4d8c-d22d-fc22ceeac29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-------+--------+------+-------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
            "+--------+------+------+----+-------+--------+------+-------+\n",
            "|     0.0|   3.0|  male|22.0|   7.25|       S|   0.0|    0.0|\n",
            "|     1.0|   1.0|female|38.0|71.2833|       C|   1.0|    1.0|\n",
            "|     1.0|   3.0|female|26.0|  7.925|       S|   1.0|    0.0|\n",
            "|     1.0|   1.0|female|35.0|   53.1|       S|   1.0|    0.0|\n",
            "+--------+------+------+----+-------+--------+------+-------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset.show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lfzlgSuKUoh6"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.drop('Sex')\n",
        "dataset = dataset.drop('Embarked')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giw_s2nyUvKG",
        "outputId": "3b486bc5-f673-4cc2-a146-4133f70d9ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+----+-------+------+-------+\n",
            "|Survived|Pclass| Age|   Fare|Gender|Boarded|\n",
            "+--------+------+----+-------+------+-------+\n",
            "|     0.0|   3.0|22.0|   7.25|   0.0|    0.0|\n",
            "|     1.0|   1.0|38.0|71.2833|   1.0|    1.0|\n",
            "|     1.0|   3.0|26.0|  7.925|   1.0|    0.0|\n",
            "|     1.0|   1.0|35.0|   53.1|   1.0|    0.0|\n",
            "+--------+------+----+-------+------+-------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset.show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SkGKYXV3UwZP"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "required_features = ['Pclass', 'Age', 'Fare', 'Gender', 'Boarded']\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
        "transformed_data = assembler.transform(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m30K1Op5VNEd",
        "outputId": "b309c3da-98c9-4659-faec-4dd330bfa061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+----+-------+------+-------+--------------------+\n",
            "|Survived|Pclass| Age|   Fare|Gender|Boarded|            features|\n",
            "+--------+------+----+-------+------+-------+--------------------+\n",
            "|     0.0|   3.0|22.0|   7.25|   0.0|    0.0|[3.0,22.0,7.25,0....|\n",
            "|     1.0|   1.0|38.0|71.2833|   1.0|    1.0|[1.0,38.0,71.2833...|\n",
            "|     1.0|   3.0|26.0|  7.925|   1.0|    0.0|[3.0,26.0,7.92500...|\n",
            "|     1.0|   1.0|35.0|   53.1|   1.0|    0.0|[1.0,35.0,53.0999...|\n",
            "+--------+------+----+-------+------+-------+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transformed_data.show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOodTx65VVYI",
        "outputId": "c777fb26-7314-4f7b-eda6-322d1bc3b841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train samples: 583\n",
            "Number of test samples: 129\n"
          ]
        }
      ],
      "source": [
        "(training_data, test_data) = transformed_data.randomSplit([0.8, 0.2])\n",
        "print(\"Number of train samples: \" + str(training_data.count()))\n",
        "print(\"Number of test samples: \" + str(test_data.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Qh-CscPZVvPe"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(labelCol='Survived',\n",
        "                            featuresCol='features',\n",
        "                            maxDepth=5)\n",
        "model = rf.fit(training_data)\n",
        "predictions = model.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9qMTDrQXVyD",
        "outputId": "14602386-d951-47b9-97fa-69d8c2766275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.829457\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Survived', predictionCol='prediction', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g\" % accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
